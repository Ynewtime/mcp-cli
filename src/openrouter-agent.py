#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ReAct MCP å®¢æˆ·ç«¯å®ç°
åŸºäº Model Context Protocol (MCP) å’Œ OpenRouter API çš„äº¤äº’å¼å·¥å…·è°ƒç”¨å®¢æˆ·ç«¯
"""

import argparse
import asyncio
import time
import sys
import threading
import logging
from typing import Optional, List, Dict, Any
from contextlib import AsyncExitStack
import datetime
import json
import re

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from openai import OpenAI
from dotenv import load_dotenv

from config import MODEL, SERVERS, REACT_PROMPT


# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


# é…ç½®æ—¥å¿—ç³»ç»Ÿ
def setup_logging(debug_mode: bool):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ

    Args:
        debug_mode: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
    """
    level = logging.DEBUG if debug_mode else logging.INFO

    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(name)s: %(message)s")

    # æ–‡ä»¶å¤„ç†å™¨ - å¤„ç†æ‰€æœ‰çº§åˆ«çš„æ—¥å¿—
    file_handler = logging.FileHandler("mcp_client.log", encoding="utf-8")
    file_handler.setFormatter(formatter)
    file_handler.setLevel(level)  # æ–‡ä»¶è®°å½•æ‰€æœ‰çº§åˆ«çš„æ—¥å¿—

    # ç»ˆç«¯å¤„ç†å™¨ - åªå¤„ç† WARNING åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    console_handler.setLevel(logging.WARNING)  # ç»ˆç«¯åªæ˜¾ç¤º WARNING åŠä»¥ä¸Š

    # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
    logging.basicConfig(level=level, handlers=[file_handler, console_handler])

    # è®¾ç½® OpenAI å®¢æˆ·ç«¯æ—¥å¿—çº§åˆ«
    logging.getLogger("openai").setLevel(logging.WARNING)


logger = logging.getLogger(__name__)


class TerminalSpinner:
    """ç»ˆç«¯æ—‹è½¬åŠ¨ç”»æŒ‡ç¤ºå™¨

    Attributes:
        message: æ˜¾ç¤ºçš„æ¶ˆæ¯
        running: æ˜¯å¦æ­£åœ¨è¿è¡Œ
        spinner_chars: åŠ¨ç”»å­—ç¬¦åºåˆ—
    """

    def __init__(self, message="å¤„ç†ä¸­..."):
        self.message = message
        self.running = False
        self.spinner_thread = None
        self.spinner_chars = ["â ‹", "â ™", "â ¹", "â ¸", "â ¼", "â ´", "â ¦", "â §", "â ‡", "â "]
        self.spinner_idx = 0
        self.is_tty = sys.stdout.isatty()

    def spin(self):
        """æ‰§è¡Œæ—‹è½¬åŠ¨ç”»"""
        while self.running:
            if self.is_tty:
                sys.stdout.write(
                    f"\r{self.spinner_chars[self.spinner_idx]} {self.message}"
                )
                sys.stdout.flush()
                self.spinner_idx = (self.spinner_idx + 1) % len(self.spinner_chars)
            time.sleep(0.1)

    def start(self, message=None):
        """å¯åŠ¨åŠ¨ç”»

        Args:
            message: å¯é€‰çš„æ–°æ¶ˆæ¯
        """
        if message:
            self.message = message
        if self.running:
            self.stop()
        self.running = True
        self.spinner_thread = threading.Thread(target=self.spin, daemon=True)
        self.spinner_thread.start()

    def stop(self):
        """åœæ­¢åŠ¨ç”»å¹¶æ¸…ç†ç»ˆç«¯è¡Œ"""
        self.running = False
        if self.spinner_thread:
            self.spinner_thread.join()
        if self.is_tty:
            sys.stdout.write(f"\r{' ' * (len(self.message) + 2)}\r")
            sys.stdout.flush()


class MCPClient:
    """MCP å®¢æˆ·ç«¯ä¸»ç±»

    Attributes:
        session: MCP å®¢æˆ·ç«¯ä¼šè¯
        openai: OpenAI å®¢æˆ·ç«¯å®ä¾‹
        tools: å¯ç”¨å·¥å…·åˆ—è¡¨
        messages: å¯¹è¯æ¶ˆæ¯å†å²
        conversation_history: å®Œæ•´å¯¹è¯å†å²è®°å½•
    """

    def __init__(self, debug_mode: bool = False):
        self.sessions: List[ClientSession] = []
        self.exit_stack = AsyncExitStack()
        self.openai = OpenAI(base_url="https://openrouter.ai/api/v1")
        self.tools = []
        self.messages = []
        self.conversation_history = []
        self.spinner = TerminalSpinner()
        self.debug_mode = debug_mode
        self.tool_to_session = {}  # å·¥å…·åç§°åˆ°ä¼šè¯çš„æ˜ å°„
        logger.info("MCPClient åˆå§‹åŒ–å®Œæˆ")

    def _sanitize_text(self, text: Any) -> str:
        """ç¡®ä¿æ–‡æœ¬æ˜¯æœ‰æ•ˆçš„ UTF-8 ç¼–ç 

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        if not isinstance(text, str):
            text = str(text)
        return text.encode("utf-8", errors="replace").decode("utf-8")

    async def connect_to_server(self, server_config: Dict[str, Any]):
        """è¿æ¥åˆ°å•ä¸ª MCP æœåŠ¡å™¨

        Args:
            server_config: å•ä¸ªæœåŠ¡å™¨é…ç½®å­—å…¸
        """
        try:
            logger.info("æ­£åœ¨è¿æ¥åˆ° MCP æœåŠ¡å™¨...")
            server_params = StdioServerParameters(**server_config)
            stdio_transport = await self.exit_stack.enter_async_context(
                stdio_client(server_params)
            )
            stdio, write = stdio_transport
            session = await self.exit_stack.enter_async_context(
                ClientSession(stdio, write)
            )
            await session.initialize()

            # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨å¹¶åˆå¹¶ï¼ŒåŒæ—¶å»ºç«‹å·¥å…·åˆ°ä¼šè¯çš„æ˜ å°„
            response = await session.list_tools()
            self.tools.extend(response.tools)
            self.sessions.append(session)
            for tool in response.tools:
                self.tool_to_session[tool.name] = session
            logger.info(
                f"æˆåŠŸè¿æ¥åˆ°æœåŠ¡å™¨ï¼Œå¯ç”¨å·¥å…·: {[tool.name for tool in response.tools]}"
            )

            # å·¥å…·åˆ—è¡¨å·²åˆå¹¶åˆ°self.toolsä¸­
            # ç³»ç»Ÿæ¶ˆæ¯å°†åœ¨process_queryä¸­ç»Ÿä¸€åˆå§‹åŒ–
        except Exception as e:
            logger.error(f"è¿æ¥æœåŠ¡å™¨å¤±è´¥: {e}")
            raise

    def _format_tools_description(self, tools: List[Any]) -> str:
        """æ ¼å¼åŒ–å·¥å…·æè¿°

        Args:
            tools: å·¥å…·åˆ—è¡¨

        Returns:
            æ ¼å¼åŒ–çš„å·¥å…·æè¿°å­—ç¬¦ä¸²
        """
        return "\n".join(
            f"å·¥å…·: {tool.name}\næè¿°: {tool.description}\nå‚æ•°:\n"
            + "\n".join(
                f"- {name}: {info.get('description', 'æ— æè¿°')}{' (å¿…å¡«)' if name in tool.inputSchema.get('required', []) else ''}"
                for name, info in tool.inputSchema["properties"].items()
            )
            + "\n"
            for tool in tools
        )

    def _convert_tool_format(self, tool: Any) -> Dict[str, Any]:
        """è½¬æ¢å·¥å…·æ ¼å¼ä¸º OpenAI å…¼å®¹æ ¼å¼

        Args:
            tool: å·¥å…·å¯¹è±¡

        Returns:
            è½¬æ¢åçš„å·¥å…·å­—å…¸
        """
        return {
            "type": "function",
            "function": {
                "name": tool.name,
                "description": tool.description,
                "parameters": {
                    "type": "object",
                    "properties": tool.inputSchema["properties"],
                    "required": tool.inputSchema.get("required", []),
                },
            },
        }

    def _sanitize_json_input(self, input_str: str) -> Optional[Dict[str, Any]]:
        """å¢å¼º JSON è§£æé²æ£’æ€§ï¼Œå¤„ç†å„ç§ JSON æ ¼å¼å˜ä½“

        Args:
            input_str: è¾“å…¥ JSON å­—ç¬¦ä¸²
        Returns:
            è§£æåçš„å­—å…¸æˆ– None
        """
        if not input_str or not isinstance(input_str, str):
            logger.debug("è¾“å…¥ä¸ºç©ºæˆ–éå­—ç¬¦ä¸²")
            return {}

        input_str = input_str.strip()
        if not input_str:
            logger.debug("è¾“å…¥ä¸ºç©ºå­—ç¬¦ä¸²")
            return {}

        original_input = input_str  # ä¿å­˜åŸå§‹è¾“å…¥ç”¨äºé”™è¯¯æŠ¥å‘Š

        # å°è¯•1: æ ‡å‡†JSONè§£æ
        try:
            return json.loads(input_str)
        except json.JSONDecodeError as e:
            logger.debug(f"æ ‡å‡†JSONè§£æå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•ã€‚é”™è¯¯: {e}")

        # å°è¯•2: å¤„ç†å•å¼•å·å­—ç¬¦ä¸²
        try:
            # æ›¿æ¢å•å¼•å·ä¸ºåŒå¼•å·ï¼Œä½†æ’é™¤è½¬ä¹‰çš„å•å¼•å·
            single_quote_fixed = re.sub(r"(?<!\\)'", '"', input_str)
            return json.loads(single_quote_fixed)
        except json.JSONDecodeError as e:
            logger.debug(f"å•å¼•å·å¤„ç†å¤±è´¥ï¼Œé”™è¯¯: {e}")

        # å°è¯•3: å¤„ç†æœªåŠ å¼•å·çš„é”®å
        try:
            # ä¸ºæœªåŠ å¼•å·çš„é”®åæ·»åŠ å¼•å·
            unquoted_keys_fixed = re.sub(
                r"([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)(\s*:)", r'\1"\2"\3', input_str
            )
            return json.loads(unquoted_keys_fixed)
        except json.JSONDecodeError as e:
            logger.debug(f"æœªåŠ å¼•å·é”®åå¤„ç†å¤±è´¥ï¼Œé”™è¯¯: {e}")

        # å°è¯•4: ç»¼åˆä¿®å¤å¸¸è§é—®é¢˜
        try:
            # 1. å¤„ç†å•å¼•å·
            fixed = re.sub(r"(?<!\\)'", '"', input_str)
            # 2. å¤„ç†æœªåŠ å¼•å·çš„é”®å
            fixed = re.sub(
                r"([{,]\s*)([a-zA-Z_][a-zA-Z0-9_]*)(\s*:)", r'\1"\2"\3', fixed
            )
            # 3. å¤„ç†å°¾éšé€—å·
            fixed = re.sub(r",\s*([}\]])", r"\1", fixed)
            # 4. å¤„ç†æœªåŠ å¼•å·çš„å€¼
            fixed = re.sub(r':\s*([^"{}\[\],\s]+)(?=\s*[,}])', r':"\1"', fixed)

            return json.loads(fixed)
        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£ææœ€ç»ˆå¤±è´¥ã€‚åŸå§‹è¾“å…¥: {original_input}ï¼Œé”™è¯¯: {e}")
            return None

    def _extract_paths_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–è·¯å¾„

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            æå–çš„è·¯å¾„åˆ—è¡¨
        """
        if not text or not isinstance(text, str):
            return []
        paths = []
        try:
            paths = re.findall(r'(/[^\s",}]+)', text)
        except re.error as e:
            logger.warning(f"æå–è·¯å¾„æ—¶æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {e}")
        if not paths:
            try:
                source_match = re.search(
                    r'["\']?source["\']?\s*:\s*["\']?([^",}]+)["\']?', text
                )
                if source_match:
                    paths.append(source_match.group(1).strip())
            except re.error as e:
                logger.warning(f"æå–æºè·¯å¾„æ—¶æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {e}")
            try:
                dest_match = re.search(
                    r'["\']?destination["\']?\s*:\s*["\']?([^",}]+)["\']?', text
                )
                if dest_match:
                    paths.append(dest_match.group(1).strip())
            except re.error as e:
                logger.warning(f"æå–ç›®æ ‡è·¯å¾„æ—¶æ­£åˆ™è¡¨è¾¾å¼é”™è¯¯: {e}")
        return paths

    def _validate_tool_parameters(
        self, tool_name: str, tool_args: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """éªŒè¯å’Œä¿®å¤å·¥å…·å‚æ•°

        Args:
            tool_name: å·¥å…·åç§°
            tool_args: å·¥å…·å‚æ•°

        Returns:
            éªŒè¯åçš„å·¥å…·å‚æ•°
        """
        if tool_args is None:
            return {}

        tool_def = next((t for t in self.tools if t.name == tool_name), None)
        if not tool_def:
            logger.warning(f"æœªæ‰¾åˆ°å·¥å…·: {tool_name}")
            return tool_args

        required_params = tool_def.inputSchema.get("required", [])
        fixed_args = tool_args.copy()

        # ç‰¹æ®Šå¤„ç† input å‚æ•°
        if "input" in fixed_args and isinstance(fixed_args["input"], str):
            input_value = fixed_args["input"].strip()
            if input_value.startswith("{"):
                parsed_input = self._sanitize_json_input(input_value)
                if parsed_input is not None:
                    fixed_args.update(parsed_input)
                    del fixed_args["input"]
                elif tool_name == "move_file":
                    paths = self._extract_paths_from_text(input_value)
                    if len(paths) >= 2:
                        fixed_args["source"] = paths[0]
                        fixed_args["destination"] = paths[1]
                        del fixed_args["input"]

        # ç‰¹å®šå·¥å…·çš„å‚æ•°ä¿®å¤
        if (
            tool_name == "list_directory"
            and "path" not in fixed_args
            and "input" in fixed_args
        ):
            fixed_args["path"] = fixed_args.pop("input")
        elif (
            tool_name == "search_files"
            and "pattern" not in fixed_args
            and "input" in fixed_args
        ):
            fixed_args["pattern"] = fixed_args.pop("input")
        elif tool_name == "move_file" and (
            "source" not in fixed_args or "destination" not in fixed_args
        ):
            paths = self._extract_paths_from_text(json.dumps(fixed_args))
            if len(paths) >= 2:
                fixed_args = {"source": paths[0], "destination": paths[1]}

        # æ£€æŸ¥å¿…å¡«å‚æ•°
        missing_params = [p for p in required_params if p not in fixed_args]
        if missing_params:
            logger.warning(f"å·¥å…· {tool_name} ç¼ºå°‘å¿…å¡«å‚æ•°: {missing_params}")

        return fixed_args

    def _print_step(self, text: str, with_spinner: bool = False, level: str = "info"):
        """æ‰“å°æ­¥éª¤ä¿¡æ¯å¹¶è®°å½•æ—¥å¿—

        Args:
            text: è¦æ‰“å°çš„æ–‡æœ¬
            with_spinner: æ˜¯å¦æ˜¾ç¤ºæ—‹è½¬åŠ¨ç”»
            level: æ—¥å¿—çº§åˆ«
        """
        self.spinner.stop()

        # è®°å½•æ—¥å¿—
        log_method = getattr(logger, level.lower(), logger.info)
        log_method(text)

        # æ‰“å°åˆ°æ§åˆ¶å°
        if with_spinner:
            self.spinner.start(text)
            time.sleep(0.5)
            self.spinner.stop()

        # æ·»åŠ é¢œè‰²å’Œæ ¼å¼
        prefixes = {
            "info": "â„¹ï¸",
            "error": "âŒ",
            "warning": "âš ï¸",
            "success": "âœ…",
            "action": "ğŸ”§",
            "thought": "ğŸ¤”",
            "observation": "ğŸ‘ï¸",
        }

        prefix = next((p for p in prefixes if p in level.lower()), "")
        if prefix:
            text = f"{prefixes[prefix]} {text}"

        print(f"{text}\n")

    async def process_query(self, query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬

        Returns:
            å¤„ç†ç»“æœ
        """
        query = self._sanitize_text(query)
        logger.info(f"å¤„ç†æŸ¥è¯¢: {query}")

        # åˆå§‹åŒ–æ¶ˆæ¯å†å²
        if not self.messages:
            tools_desc = self._format_tools_description(self.tools)
            self.messages = [
                {
                    "role": "system",
                    "content": REACT_PROMPT.format(tools_description=tools_desc),
                }
            ]

        self.messages.append({"role": "user", "content": query})

        # ç®€å•æ„å›¾è¯†åˆ«ï¼šæ£€æŸ¥æ˜¯å¦ä¸ºé—®å€™
        greetings = ["hi", "hello", "hey", "greetings", "ä½ å¥½"]
        if query.lower().strip() in greetings:
            response = "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"
            self._print_step(response, level="success")

            self.conversation_history.append(
                {
                    "query": query,
                    "response": response,
                    "timestamp": datetime.datetime.now().isoformat(),
                    "tokens": {"input": 0, "output": 0, "cost": 0.0},
                }
            )
            return response

        # è¿›å…¥ ReAct å¾ªç¯
        available_tools = [self._convert_tool_format(tool) for tool in self.tools]
        conversation_log = []
        total_input_tokens, total_output_tokens = 0, 0
        max_iterations, iterations = 100, 0
        start_time = time.time()

        while iterations < max_iterations:
            iterations += 1
            self.spinner.start(f"æ€è€ƒä¸­... (ç¬¬ {iterations} è½®)")

            try:
                logger.debug(
                    f"APIè¯·æ±‚åŸå§‹æ•°æ®: available_tools:{available_tools}; self.messages:{self.messages}"
                )
                response = self.openai.chat.completions.create(
                    model=MODEL, tools=available_tools, messages=self.messages
                )
                logger.debug(f"APIå“åº”åŸå§‹æ•°æ®: {response}")

                # è®°å½• token ä½¿ç”¨æƒ…å†µ
                if response.usage:
                    total_input_tokens += response.usage.prompt_tokens or 0
                    total_output_tokens += response.usage.completion_tokens or 0
            except Exception as e:
                self._print_step(f"è°ƒç”¨æ¨¡å‹å¤±è´¥: {e}", level="error")
                break

            self.spinner.stop()

            # è®°å½• token ä½¿ç”¨æƒ…å†µ
            if response.usage:
                total_input_tokens += response.usage.prompt_tokens or 0
                total_output_tokens += response.usage.completion_tokens or 0

            if not response.choices:
                self._print_step("é”™è¯¯: æ²¡æœ‰å¯ç”¨çš„å“åº”é€‰é¡¹", level="error")
                break

            content = response.choices[0].message
            self.messages.append(content.model_dump())
            content_text = content.content or ""
            content_text = self._sanitize_text(content_text)
            logger.debug(f"AIå“åº”: {content_text}")

            # æ£€æŸ¥æ˜¯å¦ä¸ºç›´æ¥å“åº”
            if (
                "Action:" not in content_text
                and "Thought:" not in content_text
                and not content.tool_calls
            ):
                self._print_step(f"å“åº”: {content_text}", level="success")
                break

            # æå–æ€è€ƒè¿‡ç¨‹
            reasoning = re.search(
                r"Thought: (.*?)(?=Action:|$)", content_text, re.DOTALL
            )
            reasoning = reasoning.group(1).strip() if reasoning else ""
            if reasoning:
                self._print_step(f"æ€è€ƒ: {reasoning}", level="thought")

            # å¤„ç†å·¥å…·è°ƒç”¨
            if content.tool_calls:
                # å¤„ç†æ‰€æœ‰å·¥å…·è°ƒç”¨ï¼Œè€Œä¸ä»…æ˜¯ç¬¬ä¸€ä¸ª
                for tool_call in content.tool_calls:
                    tool_name = tool_call.function.name
                    tool_args_str = tool_call.function.arguments or "{}"
                    tool_call_id = tool_call.id

                    try:
                        # è§£æå·¥å…·å‚æ•°
                        tool_args = (
                            self._sanitize_json_input(tool_args_str)
                            if tool_args_str and tool_args_str.startswith("{")
                            else {"input": tool_args_str}
                        )
                        if tool_args is None:
                            raise ValueError("æ— æ•ˆçš„JSONå‚æ•°")

                        self._print_step(
                            f"æ‰§è¡Œæ“ä½œ: {tool_name}", level="action", with_spinner=True
                        )
                        self._print_step(
                            f"æ“ä½œè¾“å…¥: {json.dumps(tool_args, indent=2, ensure_ascii=False)}",
                            level="info",
                        )

                        # éªŒè¯å’Œä¿®å¤å·¥å…·å‚æ•°
                        tool_args = self._validate_tool_parameters(tool_name, tool_args)

                        # æ‰§è¡Œå·¥å…·è°ƒç”¨
                        self.spinner.start(f"æ­£åœ¨æ‰§è¡Œ {tool_name}...")
                        logger.debug(f"è°ƒç”¨å·¥å…·: {tool_name}ï¼Œå‚æ•°: {tool_args}")
                        # ç›´æ¥é€šè¿‡å·¥å…·åç§°æ‰¾åˆ°å¯¹åº”ä¼šè¯è°ƒç”¨
                        session = self.tool_to_session.get(tool_name)
                        if not session:
                            raise RuntimeError(f"æ‰¾ä¸åˆ°å·¥å…· {tool_name} å¯¹åº”çš„ä¼šè¯")
                        result = await session.call_tool(tool_name, tool_args)
                        observation = (
                            result.content
                            if hasattr(result, "content")
                            else str(result)
                        )
                        observation = self._sanitize_text(observation)

                        self._print_step(
                            f"è§‚å¯Ÿç»“æœ: {observation}", level="observation"
                        )

                        # ä¸ºæ¯ä¸ªå·¥å…·è°ƒç”¨æ·»åŠ å“åº”æ¶ˆæ¯
                        tool_message = {
                            "role": "tool",
                            "name": tool_name,
                            "content": observation,
                            "tool_call_id": tool_call_id,
                        }
                        self.messages.append(tool_message)
                    except Exception as e:
                        error_msg = f"è°ƒç”¨ {tool_name} å¤±è´¥: {e}"
                        self._print_step(error_msg, level="error")
                        logger.error(f"å·¥å…·è°ƒç”¨å¼‚å¸¸: {error_msg}", exc_info=True)
                        self.messages.append(
                            {
                                "role": "tool",
                                "name": tool_name,
                                "content": error_msg,
                                "tool_call_id": tool_call_id,
                            }
                        )
                    finally:
                        self.spinner.stop()
            elif "Action:" in content_text:
                action = re.search(
                    r"Action:\s*(.*?)(?=\n|$)", content_text, re.IGNORECASE
                )
                action_input = re.search(
                    r"Action Input:\s*(.*?)(?=\n|Action:|$)",
                    content_text,
                    re.DOTALL | re.IGNORECASE,
                )
                if action and action_input:
                    tool_name = action.group(1).strip()
                    tool_args_str = action_input.group(1).strip()
                    if tool_name.lower() == "final answer":
                        self._print_step(f"æœ€ç»ˆç­”æ¡ˆ: {tool_args_str}", level="success")
                        break
            else:
                # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè§†ä¸ºç›´æ¥å“åº”
                self._print_step(f"å“åº”: {content_text}", level="success")
                break

        # å¤„ç†è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°çš„æƒ…å†µ
        if iterations >= max_iterations:
            self._print_step("âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œè·å–æœ€ç»ˆç­”æ¡ˆ...", level="warning")
            try:
                response = self.openai.chat.completions.create(
                    model=MODEL,
                    messages=self.messages
                    + [{"role": "user", "content": "è¯·æä¾›æœ€ç»ˆç­”æ¡ˆã€‚"}],
                )
                logger.debug(f"APIå“åº”åŸå§‹æ•°æ®: {response}")
                total_input_tokens += response.usage.prompt_tokens or 0
                total_output_tokens += response.usage.completion_tokens or 0

                # è®°å½• token ä½¿ç”¨æƒ…å†µ
                if response.usage:
                    total_input_tokens += response.usage.prompt_tokens or 0
                    total_output_tokens += response.usage.completion_tokens or 0

                final_answer = self._sanitize_text(
                    response.choices[0].message.content
                    if response.choices
                    else "æ— å¯ç”¨ç­”æ¡ˆ"
                )
                self._print_step(f"æœ€ç»ˆç­”æ¡ˆ: {final_answer}", level="success")
            except Exception as e:
                self._print_step(f"è·å–æœ€ç»ˆç­”æ¡ˆå¤±è´¥: {e}", level="error")

        # ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
        execution_time = time.time() - start_time

        summary = f"""
ä»»åŠ¡æ‰§è¡Œæ‘˜è¦:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f} ç§’
ğŸ”„ è¿­ä»£æ¬¡æ•°: {iterations}
ğŸ’¬ è¾“å…¥Tokens: {total_input_tokens:,}
ğŸ’¬ è¾“å‡ºTokens: {total_output_tokens:,}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
        self._print_step(summary, level="info")
        conversation_log.append(summary)

        # è®°å½•å¯¹è¯å†å²
        self.conversation_history.append(
            {
                "query": query,
                "response": "\n".join(conversation_log),
                "timestamp": datetime.datetime.now().isoformat(),
                "tokens": {"input": total_input_tokens, "output": total_output_tokens},
                "iterations": iterations,
            }
        )

        # é™åˆ¶æ¶ˆæ¯å†å²é•¿åº¦
        if len(self.messages) > 10:
            self.messages = [self.messages[0]] + self.messages[-8:]

        return "\n".join(conversation_log)

    async def chat_loop(self):
        """äº¤äº’å¼èŠå¤©å¾ªç¯"""
        print("\nğŸš€ ReAct MCP å®¢æˆ·ç«¯å·²å¯åŠ¨!")
        print("è¾“å…¥æŸ¥è¯¢æˆ– 'quit'/'exit'/'bye' é€€å‡º\n")

        session_start_time = datetime.datetime.now()
        total_queries = 0
        total_tokens = {"input": 0, "output": 0}

        while True:
            try:
                query = input("> è¯·è¾“å…¥æŸ¥è¯¢: ").strip()
                query = self._sanitize_text(query)

                if query.lower() in ["quit", "exit", "bye"]:
                    duration = (
                        datetime.datetime.now() - session_start_time
                    ).total_seconds()
                    summary = f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ä¼šè¯ç»Ÿè®¡:
â±ï¸ æŒç»­æ—¶é—´: {duration:.2f} ç§’
ğŸ”¢ æŸ¥è¯¢æ¬¡æ•°: {total_queries}
ğŸ’¬ æ€»è¾“å…¥Tokens: {total_tokens["input"]:,}
ğŸ’¬ æ€»è¾“å‡ºTokens: {total_tokens["output"]:,}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§!
"""
                    print(summary)
                    break

                if not query:
                    continue

                # å¤„ç†æŸ¥è¯¢
                await self.process_query(query)
                total_queries += 1

                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                latest = self.conversation_history[-1]["tokens"]
                total_tokens["input"] += latest["input"]
                total_tokens["output"] += latest["output"]

            except KeyboardInterrupt:
                print("\næ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œé€€å‡ºä¸­...")
                break
            except Exception as e:
                logger.error(f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {e}", exc_info=True)
                print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}\n")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            await self.exit_stack.aclose()
            logger.info("èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"æ¸…ç†èµ„æºæ—¶å‡ºé”™: {e}")


async def main(debug_mode: bool):
    """ä¸»å…¥å£å‡½æ•°

    Args:
        debug_mode: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
    """
    logger.info("å¯åŠ¨ MCP å®¢æˆ·ç«¯...")
    client = MCPClient(debug_mode=debug_mode)

    try:
        # Connect to all available servers
        for server_name, server_config in SERVERS.items():
            try:
                await client.connect_to_server(server_config)
                logger.info(f"æˆåŠŸè¿æ¥åˆ°æœåŠ¡å™¨: {server_name}")
            except Exception as e:
                logger.error(f"è¿æ¥æœåŠ¡å™¨ {server_name} å¤±è´¥: {e}")
                if server_name == "filesystem":
                    raise  # Re-raise if filesystem server fails as it's critical

        await client.chat_loop()
    except Exception as e:
        logger.error(f"å®¢æˆ·ç«¯è¿è¡Œå‡ºé”™: {e}", exc_info=True)
    finally:
        await client.cleanup()


if __name__ == "__main__":
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="ReAct MCP å®¢æˆ·ç«¯")
    parser.add_argument("--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ¨¡å¼")
    args = parser.parse_args()

    # é…ç½®æ—¥å¿—
    setup_logging(args.debug)

    # è¿è¡Œä¸»ç¨‹åº
    try:
        asyncio.run(main(args.debug))
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²ç»ˆæ­¢")
        sys.exit(0)
    except Exception as e:
        logger.critical(f"ç¨‹åºå´©æºƒ: {e}", exc_info=True)
        sys.exit(1)
